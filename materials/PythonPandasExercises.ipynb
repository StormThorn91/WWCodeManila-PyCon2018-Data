{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Hello, World of Data!\": Your ABC Blocks in Data Handling, Analysis, and Visualization  \n",
    "## Section 2: Kung Fu Pandas\n",
    "Data Handling using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python pandas library - storing and manipulating data in \"dataframes\" (tables)\n",
    "\n",
    "Data pre-processing makes up a non-trivial chunk of a typical analysis workflow.  Even before any actual analysis begins, analysts find themselves needing to inspect elements, painstakingly uniformize format, check for and impute missing data, regularize variables, subset the data, and many similar activities.  In addition, during analysis proper, data are constantly being massaged every which way to fit the requirements of the analysis.\n",
    "\n",
    "Data handling kung fu is therefore a very important skill to have when analyzing data.  \n",
    "\n",
    "So what tool/s can one use for data handling?  \n",
    "\n",
    "For small, infrequent analyses, spreadsheets can often do the trick.  MS Excel, Libre Office Calculator, and Google Spreadsheets are all great tools that get the basics done quickly with very little investment in learning.\n",
    "\n",
    "But as the data scales up, the time doing manual input also scales linearly.  The same 5-min task for 100 cells takes more than a month for 1M cells--if you never sleep.  One can do scripting from within the spreadsheets, and that's fine if your laptop/desktop doesn't slow down loading the data to the GUI, which it will.  Or perhaps, your spreadsheet won't even load all your data, because of the limit in columns and rows that the software can load.  And what if this is a task that you have to do on a regular basis?  Maybe you're better off using another tool?\n",
    "\n",
    "Enter python + the pandas library.\n",
    "\n",
    "Pandas can do everything that you can do in a spreadsheet, and more!  Sky's the limit on rows or columns in pandas (rather, your RAM :P ).  It's fast, and scales well with data.  Best of all, it's easy to automate.  Because of all these, pandas has been seeing a steep growth since its introduction in 2011.  In Stackoverflow, pandas-tagged queries have been seeing the highest rate of traffic among other most asked-about python frameworks/libraries.  Finally, in 2018, the pandas tag received the highest traffic.\n",
    "\n",
    "![title](related_tags_over_time_from-stackoverflow_small.png)\n",
    "Image source: https://stackoverflow.blog/2017/09/14/python-growing-quickly/\n",
    "\n",
    "And it's not just among Python users.  With the growth in popularity of data analysis, the pandas library come to eat one of biggest shares in Stackoverflow traffic across all platforms. Below, the 'data science' cluster makes up the largest cluster, and pandas is at the center of it. \n",
    "\n",
    "![title](tag_network_graph-1_from-stackoverflow_small.png)\n",
    "Image source: https://stackoverflow.blog/2017/09/14/python-growing-quickly/\n",
    "\n",
    "All these point to how important the pandas library is in analyzing data (and there's a big chance the data used above were also handled using pandas).\n",
    "\n",
    "And so without further ado, let's do data kung fu, pandas style!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For compatibility across multiple platforms\n",
    "import os\n",
    "IB = os.environ.get('INSTABASE_URI',None) is not None\n",
    "open = ib.open if IB else open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from CSV file into dataframe\n",
    "To manipulate your data using pandas, you must be able to import them first.  \n",
    "\n",
    "A pandas.DataFrame object is simply a table, which means that you can convert your tabular data into a dataframe.\n",
    "\n",
    "Here's how to import a CSV file into a pandas dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = pd.read_csv('Cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that your csv file may not open correctly using default `pd.read_csv()`, so review the documentation in case you need to change some parameters to open the file the way you want to.\n",
    "\n",
    "Pandas can also import other forms of tabular data.  Check it out here: https://pandas.pydata.org/pandas-docs/stable/io.html\n",
    "\n",
    "After importing your data, you can check it several ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows, columns\n",
    "cities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of rows\n",
    "len(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the number of rows/elements (not the number of columns) is interpreted as the size of the dataframe.  And in fact, if you try `cities.size`, it will give you the same answer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First few rows\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 20 rows\n",
    "cities.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All column names\n",
    "cities.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe has several more attributes and functions that are useful in the initial ispection of imported data (i.e., checking data types, checking for missing elements)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting, selecting rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe can be sorted by one or more columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sorting by country then descending temperature\n",
    "cities.sort_values(['country','temperature'],ascending=[True,False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the function does not change the original dataframe.  It simply returns a sorted copy of it.  Check the original dataframe again.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single column can be selected from the dataframe.  The returned object is a pandas.Series object, which, as the name implies, is simply a series of data points that are indexed.  \n",
    "\n",
    "There are two different ways of selecting a column.  You can select a column by treating it as a dataframe attribute (below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a single column - returns a 'series'\n",
    "city_names = cities.city\n",
    "city_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the indices have been carried over from the original dataframe.  Let us inspect whether indeed `cities` is a `pandas.Series` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(city_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns can also be selected by label/index, or using `[]`.  This is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection by indexing\n",
    "cities['city']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection by index is flexible.  It allows multiple column selection (returns a dataframe).  To specify mulitple columns, they must be in a list so that the specification is still provided as a single object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting multiple columns - returns a dataframe\n",
    "cities[['city','temperature']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows can also be selected in a dataframe, by slicing usign their number indices.  Here's how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows by number\n",
    "cities[15:20]\n",
    "# Show cities[:8] and cities[200:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that although you can select by column using a string (or list of strings) when directly using `[]`,  using numbers or slices of numbers will select rows.  \n",
    "\n",
    "One can also select rows using conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.longitude < 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operation above returns a series of boleans.  You can use such an operation to construct a conditional for selecting rows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows based on condition\n",
    "# Note: no need to do type conversion - pandas infers types for columns\n",
    "cities[cities.longitude < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update what we know so far.  When directly using brackets `[]` to select from a dataframe, number/index slices or bolean arrays will select by row.  On the other hand, string labels or a list of string labels will select by column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting it together: selecting rows, selecting columns, sorting:\n",
    "# City and longitude of all cities with latitude > 50 and\n",
    "# temperature > 9, sorted by longitude\n",
    "temp1 = cities[(cities.latitude > 50) & (cities.temperature > 9)]\n",
    "temp2 = temp1[['city','longitude']]\n",
    "temp3 = temp2.sort_values('longitude')\n",
    "temp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though flexible, directly using brackets `[]` limits selection to a single dimension. There are other, multidimensional ways to select from a dataframe that are more precise and gives more control and flexibility.  \n",
    "\n",
    "To select using label indices, use `.loc`. To select using positional indices, use `.iloc`.  \n",
    "\n",
    "For either `.loc` or `.iloc` dataframe indexers, the first argument is the row_indexer, the second argument is the column_indexer.\n",
    "\n",
    "Let's recreate what we did above using the `.loc` indexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp4 = cities.loc[(cities.latitude > 50) & (cities.temperature > 9), \n",
    "                   ['city','longitude']]\n",
    "temp5 = temp4.sort_values('longitude') \n",
    "temp5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Your Turn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all countries that are not in the EU and don't have coastline, together with their populations, sorted by population (smallest to largest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 'Countries.csv' file into a dataframe\n",
    "countries = pd.read_csv('Countries.csv')\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation\n",
    "We can perform various functions to summarize data along columns and/or rows, or within specific groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum and maximum temperature\n",
    "print(f'Minimum temperature:\\t{min(cities.temperature)}')\n",
    "print(f'Maximum temperature:\\t{max(cities.temperature)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average temperature\n",
    "print('Using sum/count:', sum(cities.temperature)/len(cities.temperature))\n",
    "import numpy as np\n",
    "print('Using numpy:', np.average(cities.temperature))\n",
    "print('Using built-in mean:', cities.temperature.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also group the data according to entries in one or more columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average temperature of cities in each country\n",
    "cities.groupby('country').mean().temperature\n",
    "# or [['temperature']]\n",
    "# Also show without column selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Your Turn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Find the average population of countries with coastline, and countries without coastline.  \n",
    "Hint: You can use groupby!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Modify to group by both coastline and EU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cities.merge(countries, on='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining is symmetric\n",
    "countries.merge(cities, on='country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the many features of pandas is the built-in ability to perform string operations on its elements--whether to modify the data or to use it for condidionals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String operations - countries with 'ia' in their name\n",
    "countries[countries.country.str.contains('ia')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also perform simple plotting from within pandas itself, but more on this later.  Here is a simple demo for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "%matplotlib inline\n",
    "cities.plot.scatter(x='latitude', y='temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And apart from string operations, one can also perform actual mathematical operations along and between columns, in a very straightforward way! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fahrenheit column\n",
    "cities['fahrenheit'] = (cities.temperature * 9/5) + 32\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Queries\" - only last result shown\n",
    "cities[cities.longitude > 35]\n",
    "cities[cities.longitude < -5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment to temporary dataframes\n",
    "# (modify to show both east and west)\n",
    "east = cities[cities.longitude > 35]\n",
    "west = cities[cities.longitude < -5]\n",
    "east\n",
    "west"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Your Turn: World Cup data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the Players and Teams data into dataframes\n",
    "players = pd.read_csv('Players.csv')\n",
    "teams = pd.read_csv('Teams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Q1: What player on a team with “ia” in the team name played less than\n",
    "200 minutes and made more than 100 passes? Print the player surname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.loc[(players.team.str.contains(\"ia\") & \\\n",
    "            (players.minutes < 200) & \\\n",
    "            (players.passes > 100)), \n",
    "            \"surname\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Q2: What is the average number of passes made by forwards? By midfielders?  Don't include any other positions in your result.  \n",
    "Hint: groupby is NOT the easiest way to do this one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Q3: Which team has the highest ratio of goalsFor to goalsAgainst?  \n",
    "Print the team name only.  \n",
    "Hint: There are several ways to do this, but a good way to start is to add a \"ratio\" column to the teams dataframe, and go from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Q4: How many players who play on a team with ranking `<10` played more than 350 minutes?  \n",
    "Reminder: There are several ways to check the shape and size of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__BONUS!__\n",
    "Write a loop that interactively asks the user to enter a team name.  \n",
    "If the team exists, list all of the players on that team (with all of their information), sorted by descending minutes played.  \n",
    "If the team doesn't exist, print \"Team not in 2010 World Cup\".  \n",
    "If 'quit' is entered, terminate the loop.  \n",
    "\n",
    "Reminder: To read a string from the user instead of a number, use input().  \n",
    "Note: To test if a value v is (not) in a column c of a dataframe D,\n",
    "use \"v not in D.c.values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
